{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Tweet    Text Label\n",
      "0     .omg why are poc wearing fugly blue contacts s...  Non-Bullying\n",
      "1     .Sorry but most of the runners popular right n...  Non-Bullying\n",
      "2     .those jeans are hideous, and I?m afraid he?s ...  Non-Bullying\n",
      "3     .I had to dress up for a presentation in class...  Non-Bullying\n",
      "4     .Am I the only one who thinks justin bieber is...  Non-Bullying\n",
      "...                                                 ...           ...\n",
      "1060  No we are not, But you are a race baiting libt...      Bullying\n",
      "1061  you wont get anyone for this challenge., after...      Bullying\n",
      "1062  I will follow you if you are not a libtard,Mus...      Bullying\n",
      "1063  michaelianblack Ur a child, an ostrich w/ your...      Bullying\n",
      "1064  FoxNews. not to all the ppl I know that live t...      Bullying\n",
      "\n",
      "[1065 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\R.Dharshini/nltk_data'\n    - 'C:\\\\Users\\\\R.Dharshini\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\R.Dharshini\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\R.Dharshini\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\R.Dharshini\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f56751bce17f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#tokenize words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;31m#remove punctuations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mclean_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    878\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\R.Dharshini/nltk_data'\n    - 'C:\\\\Users\\\\R.Dharshini\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\R.Dharshini\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\R.Dharshini\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\R.Dharshini\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "#Same modeling, slightly different code with similar results\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "#import dataset\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"cleanprojectdataset.csv\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "print(df1)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "#Create lists for tweets and label\n",
    "Tweet = []\n",
    "Labels = []\n",
    "\n",
    "for row in df1[\"Tweet\"]:\n",
    "    #tokenize words\n",
    "    words = word_tokenize(row)\n",
    "    #remove punctuations\n",
    "    clean_words = [word.lower() for word in words if word not in set(string.punctuation)]\n",
    "    #remove stop words\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\" ]\n",
    "    clean_words = [word for word in clean_words if word not in english_stops]\n",
    "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
    "    #Lematise words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
    "    Tweet.append(lemma_list)\n",
    "\n",
    "    for row in df1[\"Text Label\"]:\n",
    "        Labels.append(row)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "#Combine lists\n",
    "combined = zip(Tweet, Labels)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "#Create bag of words\n",
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "#Create new list for modeling\n",
    "Final_Data = []\n",
    "for r, v in combined:\n",
    "    bag_of_words(r)\n",
    "    Final_Data.append((bag_of_words(r),v))\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data)\n",
    "print(len(Final_Data))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "#Split the data into training and test\n",
    "train_set, test_set = Final_Data[0:746], Final_Data[746:]\n",
    "\n",
    "#Naive Bayes for Unigramsm check accuracy\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "print(\"Naive Bayes Performance with Unigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "#Naive Bayes for Unigrams, Recall Measure\n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "nbrefset = collections.defaultdict(set)\n",
    "nbtestset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    nbrefset[label].add(i)\n",
    "    observed = nb_classifier.classify(feats)\n",
    "    nbtestset[observed].add(i)\n",
    "print(\"UnigramNB Recall\")\n",
    "print('Bullying recall:', recall(nbtestset['Bullying'], nbrefset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "#Find most informative features\n",
    "classifier.show_most_informative_features(n=10)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "#Decision Tree for Unigrams\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"UnigramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "#Logisitic Regression for Unigrams\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"UnigramsLogit Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    " \n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "#Support Vector Machine for Unigrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"UnigramSVM Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "#Same thing with Bigrams\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "combined = zip(Tweet,Labels)\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "#Bag of Words of Bigrams\n",
    "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)  \n",
    "    bigrams = bigram_finder.nbest(score_fn, n)  \n",
    "    return bag_of_words(bigrams)\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "Final_Data2 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_bigrams_words(z)\n",
    "    Final_Data2.append((bag_of_bigrams_words(z),e))\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data2)\n",
    "print(len(Final_Data2))\n",
    "\n",
    "train_set, test_set = Final_Data2[0:747], Final_Data2[747:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "#Naive Bayes for Bigrams\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance with Bigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "classifier.show_most_informative_features(n=10)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "print(\"BigramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "#Decision Tree for Bigrams\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"BigramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "#Logistic Regression for Bigrams\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"BigramsLogit Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    " \n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "#Support Vector Machine for Bigrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"Bigrams Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "combined = zip(Tweet,Labels)\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "#Same thing with Trigrams\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "def bag_of_trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq, n=200):\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(words)  \n",
    "    trigrams = trigram_finder.nbest(score_fn, n)  \n",
    "    return bag_of_words(trigrams)\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "Final_Data3 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_trigrams_words(z)\n",
    "    Final_Data3.append((bag_of_trigrams_words(z),e))\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data3)\n",
    "print(len(Final_Data3))\n",
    "\n",
    "train_set, test_set = Final_Data3[0:747], Final_Data3[747:]\n",
    "\n",
    "#Naive Bayes for Trigrams\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance with Trigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "classifier.show_most_informative_features(n=10)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "#Decision Tree for Trigrams\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"TrigramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "#Logistic Regression for Trigrams\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"TrigramsLogit Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "#Support Vector Machine for Trigrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"Trigrams Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "combined = zip(Tweet,Labels)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "#Combine both unigrams, bigrams, and trigrams\n",
    "\n",
    "# Import Bigram metrics - we will use these to identify the top 200 bigrams\n",
    "def bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq,\n",
    "n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return bigrams\n",
    "\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "# Import Bigram metrics - we will use these to identify the top 200 trigrams \n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "def trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq,\n",
    "n=200):\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(words)\n",
    "    trigrams = trigram_finder.nbest(score_fn, n)\n",
    "    return trigrams\n",
    "\n",
    "#bag of ngrams\n",
    "def bag_of_Ngrams_words(words):\n",
    "    bigramBag = bigrams_words(words)\n",
    "    \n",
    "    #The following two for loops convert tuple into string\n",
    "    for b in range(0,len(bigramBag)):\n",
    "        bigramBag[b]=' '.join(bigramBag[b])\n",
    "   \n",
    "    trigramBag = trigrams_words(words)\n",
    "    for t in range(0,len(trigramBag)):\n",
    "        trigramBag[t]=' '.join(trigramBag[t])\n",
    "\n",
    "    return bag_of_words(trigramBag + bigramBag + words)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "Final_Data4 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_Ngrams_words(z)\n",
    "    Final_Data4.append((bag_of_Ngrams_words(z),e))\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data4)\n",
    "print(len(Final_Data4))\n",
    "\n",
    "train_set, test_set = Final_Data4[0:747], Final_Data4[747:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "#Naive Bayes for Ngrams\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance with Ngrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "classifier.show_most_informative_features(n=10)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "#Decision Tree for Ngrams\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"NgramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "#Logistic Regression for Ngrams\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"NgramsLogit Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "#Support Vector Machine for Ngrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"Trigrams Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "train_set, test_set = Final_Data[0:747], Final_Data[747:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nb_classifier.show_most_informative_features(10)\n",
    "\n",
    "from nltk.classify.util import accuracy\n",
    "print(accuracy(nb_classifier, test_set))\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "    \n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = nb_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
    "print('not-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('not-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('not-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "import collections\n",
    "from nltk import metrics\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "from nltk.classify.util import accuracy\n",
    "print(accuracy(dt_classifier, test_set))\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "    \n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = dt_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
    "print('non-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('non-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('non-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "#Create Logistic Regression model to compare\n",
    "from nltk.classify import MaxentClassifier\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    " \n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = logit_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "  \n",
    "print('pos precision:', precision(refsets['Bullying'], testsets['Non-Bullying']))\n",
    "print('pos recall:', recall(refsets['Bullying'], testsets['Non-Bullying']))\n",
    "print('pos F-measure:', f_measure(refsets['Bullying'], testsets['Non-Bullying']))\n",
    "print('neg precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('neg recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('neg F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "# SVM model\n",
    "\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    "\n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = SVM_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print('pos precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('pos recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "print('pos F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
    "print('neg precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('neg recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('neg F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "zl = zip(Tweet,Labels)\n",
    "\n",
    "#define a bag_of_words function to return word, True.\n",
    "\n",
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "def bag_of_words_not_in_set(words, badwords):\n",
    "    return bag_of_words(set(words) - set(badwords))\n",
    "\n",
    "# Define another function that will return words that are in words, but not in badwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#define a bag_of_non_stopwords function to return word, True.\n",
    "\n",
    "def bag_of_non_stopwords(words, stopfile='english'):\n",
    "    badwords = stopwords.words(stopfile)\n",
    "    return bag_of_words_not_in_set(words, badwords)\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "# Import Bigram metrics - we will use these to identify the top 200 bigrams\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return bag_of_words(bigrams)\n",
    "    \n",
    "    bigrams = bag_of_bigrams_words(words)\n",
    "\n",
    "#Creating our unigram featureset dictionary for modeling\n",
    "\n",
    "Final_Data = []\n",
    "\n",
    "for k, v in zl:\n",
    "    bag_of_bigrams_words(k)\n",
    "    Final_Data.append((bag_of_bigrams_words(k),v))\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data)\n",
    "\n",
    "#splits the data around 70% of 500 *350 reviews* for both testing and training\n",
    "\n",
    "train_set, test_set = Final_Data[0:778], Final_Data[778:]\n",
    "\n",
    "#Now we will calculate accuracy, precision, recall, and f-measure using Naives Bayes classifier\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nb_classifier.show_most_informative_features(10)\n",
    "\n",
    "from nltk.classify.util import accuracy\n",
    "print(accuracy(nb_classifier, test_set))\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "    \n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = nb_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
    "print('not-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('not-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('not-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "def bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq,\n",
    "n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return bigrams\n",
    "\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "# Import Bigram metrics - we will use these to identify the top 200 bigrams\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "def trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq,\n",
    "n=200):\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(words)\n",
    "    trigrams = trigram_finder.nbest(score_fn, n)\n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bag_of_Ngrams_words(words):\n",
    "    bigramBag = bigrams_words(words)\n",
    "    \n",
    "    #The following two for loops convert tuple into string\n",
    "    for b in range(0,len(bigramBag)):\n",
    "        bigramBag[b]=' '.join(bigramBag[b])\n",
    "   \n",
    "    trigramBag = trigrams_words(words)\n",
    "    for t in range(0,len(trigramBag)):\n",
    "        trigramBag[t]=' '.join(trigramBag[t])\n",
    "\n",
    "    return bag_of_words(trigramBag + bigramBag + words)\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "zl = zip(Tweet,Labels)\n",
    "\n",
    "Final_Data = []\n",
    "\n",
    "for k, v in zl:\n",
    "    bag_of_words(k)\n",
    "    Final_Data.append((bag_of_words(k),v))\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data)\n",
    "\n",
    "#splits the data around 70% of 500 *350 reviews* for both testing and training\n",
    "\n",
    "train_set, test_set = Final_Data[0:778], Final_Data[778:]\n",
    "\n",
    "#Now we will calculate accuracy, precision, recall, and f-measure using Naives Bayes classifier\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nb_classifier.show_most_informative_features(10)\n",
    "\n",
    "from nltk.classify.util import accuracy\n",
    "print(accuracy(nb_classifier, test_set))\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "    \n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = nb_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
    "print('not-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('not-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('not-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "import collections\n",
    "from nltk import metrics\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "from nltk.classify.util import accuracy\n",
    "print(accuracy(dt_classifier, test_set))\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "    \n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = dt_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
    "print('non-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('non-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('non-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "#Create Logistic Regression model to compare\n",
    "from nltk.classify import MaxentClassifier\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    " \n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = logit_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "  \n",
    "print('pos precision:', precision(refsets['Bullying'], testsets['Non-Bullying']))\n",
    "print('pos recall:', recall(refsets['Bullying'], testsets['Non-Bullying']))\n",
    "print('pos F-measure:', f_measure(refsets['Bullying'], testsets['Non-Bullying']))\n",
    "print('neg precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('neg recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('neg F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "# SVM model\n",
    "\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    "\n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = SVM_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print('pos precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('pos recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "print('pos F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
    "print('neg precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('neg recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('neg F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]:\n",
    "\n",
    "#Tokenize words and labels into lists\n",
    "\n",
    "Tweet = []\n",
    "Labels = []\n",
    "\n",
    "for row in df1[\"Tweet\"]:\n",
    "    #tokenize words\n",
    "    words = word_tokenize(row)\n",
    "    #remove punctuations\n",
    "    clean_words = [word.lower() for word in words if word not in set(string.punctuation)]\n",
    "    #remove stop words\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\" ]\n",
    "    clean_words = [word for word in clean_words if word not in english_stops]\n",
    "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
    "    #Lematise words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
    "    Tweet.append(lemma_list)\n",
    "\n",
    "    for row in df1[\"Text Label\"]:\n",
    "        Labels.append(row)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "#combine them to create bag of words\n",
    "combined = zip(Tweet, Labels)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "#Create bag of words and dictionary object\n",
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "#Key, Value Pair into new list for modeling\n",
    "Final_Data = []\n",
    "for r, v in combined:\n",
    "    bag_of_words(r)\n",
    "    Final_Data.append((bag_of_words(r),v))\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "#random shuffle\n",
    "import random\n",
    "random.shuffle(Final_Data)\n",
    "print(len(Final_Data))\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "#Split the data into training set and testing 60/40 split\n",
    "train_set, test_set = Final_Data[0:746], Final_Data[746:]\n",
    "\n",
    "#import confusion matrix metrics and run Naive Bayes with Unigrams\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "#find accuracy\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance with Unigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "#find recall\n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "nbrefset = collections.defaultdict(set)\n",
    "nbtestset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    nbrefset[label].add(i)\n",
    "    observed = nb_classifier.classify(feats)\n",
    "    nbtestset[observed].add(i)\n",
    "print(\"UnigramNB Recall\")\n",
    "print('Bullying recall:', recall(nbtestset['Bullying'], nbrefset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "#find most informative features\n",
    "classifier.show_most_informative_features(n=10)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "#Run Decision Tree for Unigrams to find recall\n",
    "\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"UnigramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "#Run Maxent Classifier for Unigrams\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"UnigramsLogit Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    " \n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "#Run Support Vector Machine for Unigrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"UniigramSVM Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "#Do the same thing with bigrams\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "combined = zip(Tweet,Labels)\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "#Bag of words for bigrams\n",
    "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)  \n",
    "    bigrams = bigram_finder.nbest(score_fn, n)  \n",
    "    return bag_of_words(bigrams)\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "Final_Data2 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_bigrams_words(z)\n",
    "    Final_Data2.append((bag_of_bigrams_words(z),e))\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data2)\n",
    "print(len(Final_Data2))\n",
    "\n",
    "#split data again around 60/40\n",
    "\n",
    "train_set, test_set = Final_Data2[0:747], Final_Data2[747:]\n",
    "\n",
    "#Naive Bayes for Bigrams\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "#Accuracy\n",
    "\n",
    "print(\"Naive Bayes Performance with Bigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "#Informative Features for Bigrams\n",
    "classifier.show_most_informative_features(n=10)\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "#Decision Tree for Bigrams\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"BigramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "#Maxent Classifier for Bigrams\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"BigramsLogit Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    " \n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "#Support Vecotr Machine for Bigrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"Bigrams Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "combined = zip(Tweet,Labels)\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "#Same thing with Trigrams\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "#Bag of words for Trigrams\n",
    "def bag_of_trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq, n=200):\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(words)  \n",
    "    trigrams = trigram_finder.nbest(score_fn, n)  \n",
    "    return bag_of_words(trigrams)\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "#Final list for modeling\n",
    "Final_Data3 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_trigrams_words(z)\n",
    "    Final_Data3.append((bag_of_trigrams_words(z),e))\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data3)\n",
    "print(len(Final_Data3))\n",
    "\n",
    "#60/40\n",
    "train_set, test_set = Final_Data3[0:747], Final_Data3[747:]\n",
    "\n",
    "#Naive Bayes for Trigrams\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "#Accuracy\n",
    "print(\"Naive Bayes Performance with Trigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "#Metrics\n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "#Most informative features for Trigrams\n",
    "classifier.show_most_informative_features(n=10)\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "#Decision Tree for Trigrams\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"TrigramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "#Maxent Classifier for Trigrams\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"TrigramsLogit Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "#Support Vector Machine for Trigrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"Trigrams Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "combined = zip(Tweet,Labels)\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "#Combining Unigrams, Bigrams, and Trigrams for (N=3) modeling\n",
    "\n",
    "# Import Bigram metrics - we will use these to identify the top 200 trigrams\n",
    "def bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq,\n",
    "n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return bigrams\n",
    "\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "# Import Trigram metrics - we will use these to identify the top 200 trigrams\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "def trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq,\n",
    "n=200):\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(words)\n",
    "    trigrams = trigram_finder.nbest(score_fn, n)\n",
    "    return trigrams\n",
    "\n",
    "#Combined\n",
    "def bag_of_Ngrams_words(words):\n",
    "    bigramBag = bigrams_words(words)\n",
    "    \n",
    "    #The following two for loops convert tuple into string\n",
    "    for b in range(0,len(bigramBag)):\n",
    "        bigramBag[b]=' '.join(bigramBag[b])\n",
    "   \n",
    "    trigramBag = trigrams_words(words)\n",
    "    for t in range(0,len(trigramBag)):\n",
    "        trigramBag[t]=' '.join(trigramBag[t])\n",
    "        \n",
    " #New bag of words\n",
    "\n",
    "    return bag_of_words(trigramBag + bigramBag + words)\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "Final_Data4 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_Ngrams_words(z)\n",
    "    Final_Data4.append((bag_of_Ngrams_words(z),e))\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "#Naive Bayes for Ngrams\n",
    "import random\n",
    "random.shuffle(Final_Data4)\n",
    "print(len(Final_Data4))\n",
    "\n",
    "train_set, test_set = Final_Data4[0:747], Final_Data4[747:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "#Accuracy\n",
    "print(\"Naive Bayes Performance with Ngrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "#Informative features for Ngrams\n",
    "classifier.show_most_informative_features(n=10)\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "#Decision Tree for Ngrams\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"NgramDT Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "#Maxent Classifier, Logistic Regression for Ngrams\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "print(\"NgramsLogit Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "#Support Vector Machine for Ngrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"Ngrams Recall\")\n",
    "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
    "\n",
    "\n",
    "#Printing with more measures, example below\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "train_set, test_set = Final_Data[0:747], Final_Data[747:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nb_classifier.show_most_informative_features(10)\n",
    "\n",
    "from nltk.classify.util import accuracy\n",
    "print(accuracy(nb_classifier, test_set))\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "    \n",
    "for i, (Final_Data, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = nb_classifier.classify(Final_Data)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
    "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
    "print('not-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('not-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
    "print('not-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
